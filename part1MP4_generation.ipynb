{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EYMwyojZe0JQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-05 20:18:23--  https://raw.githubusercontent.com/Junting98/language_data/master/language_data.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25976656 (25M) [application/zip]\n",
      "Saving to: ‘language_data.zip’\n",
      "\n",
      "language_data.zip   100%[===================>]  24.77M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2023-04-05 20:18:23 (407 MB/s) - ‘language_data.zip’ saved [25976656/25976656]\n",
      "\n",
      "/bin/bash: unzip: command not found\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unidecode in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (1.3.4)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env bash\n",
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/Junting98/language_data/master/language_data.zip\n",
    "\n",
    "!unzip language_data.zip\n",
    "!rm language_data.zip\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cz9h83GeeD8w"
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "def read_file(filename):\n",
    "    file = unidecode.unidecode(open(filename).read())\n",
    "    return file, len(file)\n",
    "\n",
    "# Turning a string into a tensor\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string), requires_grad=True).long()\n",
    "    for c in range(len(string)):\n",
    "        try:\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        except:\n",
    "            continue\n",
    "    return tensor\n",
    "\n",
    "# Readable time elapsed\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K1MzeENdeHez"
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "# from rnn.helpers import *\n",
    "# from rnn.model import *\n",
    "\n",
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, device=None):\n",
    "    hidden = decoder.init_hidden(1, device=device)\n",
    "    prime_input = char_tensor(prime_str).unsqueeze(0).to(device)\n",
    "\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "      _, hidden = decoder(prime_input[:,p], hidden)\n",
    "        \n",
    "    inp = prime_input[:,-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "      output, hidden = decoder(inp, hidden)\n",
    "      \n",
    "      # Sample from the network as a multinomial distribution\n",
    "\n",
    "      output_dist = output.data.view(-1).div(temperature).exp()\n",
    "      top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "      # Add predicted character to string and use as next input\n",
    "      predicted_char = all_characters[top_i]\n",
    "      predicted += predicted_char\n",
    "      inp = char_tensor(predicted_char).unsqueeze(0).to(device)\n",
    "\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ts1KPw9dvOH"
   },
   "source": [
    "# Generating Text with an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sSXvCz5VdvOL"
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7tzouekHdvOO"
   },
   "outputs": [],
   "source": [
    "# from rnn.model import RNN\n",
    "# from rnn.helpers import time_since\n",
    "# from rnn.generate import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5lLA0w_GdvOO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9M0QlqIIdvOO"
   },
   "source": [
    "## Data Processing\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package (which you can install via `pip` or `conda`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_KW7yEddvOP",
    "outputId": "7afef722-d179-48cf-b2ff-306947dd33dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n",
      "train len:  1003854\n",
      "test len:  111540\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file_path = 'language_data/shakespeare.txt'\n",
    "file = unidecode.unidecode(open(file_path).read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)\n",
    "\n",
    "# we will leave the last 1/10th of text as test\n",
    "\n",
    "split = int(0.9*file_len)\n",
    "train_text = file[:split]\n",
    "test_text = file[split:]\n",
    "\n",
    "print('train len: ', len(train_text))\n",
    "print('test len: ', len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E00bs3FXdvOP",
    "outputId": "4b30f1c2-d1b8-444b-b752-6d59665e6cad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\n",
      "The sly slow hours shall not determinate\n",
      "The dateless limit of thy dear exile;\n",
      "The hopeless word of 'never to return'\n",
      "Breathe I against thee, upon pain of life.\n",
      "\n",
      "THOMAS MOWBRAY:\n",
      "A heavy sentence, my\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk(text):\n",
    "    start_index = random.randint(0, len(text) - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return text[start_index:end_index]\n",
    "\n",
    "print(random_chunk(train_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUDxnGkGdvOP"
   },
   "source": [
    "### Input and Target data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q0H44jQdvOQ"
   },
   "source": [
    "To make training samples out of the large string of text data, we will be splitting the text into chunks.\n",
    "\n",
    "Each chunk will be turned into a tensor, specifically a `LongTensor` (used for integer values), by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MdISwtCLdvOQ"
   },
   "outputs": [],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string), requires_grad=True).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqnEonr7dvOQ"
   },
   "source": [
    "The following function loads a batch of input and target tensors for training. Each sample comes from a random chunk of text. A sample input will consist of all characters *except the last*, while the target wil contain all characters *following the first*. For example: if random_chunk='abc', then input='ab' and target='bc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RBKeZCf7dvOR"
   },
   "outputs": [],
   "source": [
    "def load_random_batch(text, chunk_len, batch_size):\n",
    "    input_data = torch.zeros(batch_size, chunk_len).long().to(device)\n",
    "    target = torch.zeros(batch_size, chunk_len).long().to(device)\n",
    "    for i in range(batch_size):\n",
    "        start_index = random.randint(0, len(text) - chunk_len - 1)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = text[start_index:end_index]\n",
    "        input_data[i] = char_tensor(chunk[:-1])\n",
    "        target[i] = char_tensor(chunk[1:])\n",
    "    return input_data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMAyEZxQdvOR"
   },
   "source": [
    "# Implement model\n",
    "\n",
    "Your RNN model will take as input the character for step $t_{-1}$ and output a prediction for the next character $t$. The model should consiste of three layers - a linear layer that encodes the input character into an embedded state, an RNN layer (which may itself have multiple layers) that operates on that embedded state and a hidden state, and a decoder layer that outputs the predicted character scores distribution.\n",
    "\n",
    "\n",
    "You must implement your model in the `rnn/model.py` file. You should use a `nn.Embedding` object for the encoding layer, a RNN model like `nn.RNN` or `nn.LSTM`, and a `nn.Linear` layer for the final a predicted character score decoding layer.\n",
    "\n",
    "\n",
    "**TODO:** Implement the model in RNN `rnn/model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsGCl4q7dvOS"
   },
   "source": [
    "# Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time.\n",
    "\n",
    "\n",
    "Note that in the `evaluate` function, every time a prediction is made the outputs are divided by the \"temperature\" argument. Higher temperature values make actions more equally likely giving more \"random\" outputs. Lower temperature values (less than 1) high likelihood options contribute more. A temperature near 0 outputs only the most likely outputs.\n",
    "\n",
    "You may check different temperature values yourself, but we have provided a default which should work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mrVOv2z_dvOS"
   },
   "outputs": [],
   "source": [
    "def evaluate(rnn, prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = rnn.init_hidden(1, device=device)\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = rnn(prime_input[p].unsqueeze(0).to(device), hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = rnn(inp.unsqueeze(0).to(device), hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "frWiYe-hyMo3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model_type=\"rnn\", n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.model_type = model_type\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        embedded_input = self.embedding(input)\n",
    "\n",
    "        if self.model_type == \"rnn\":\n",
    "          output, hidden = self.rnn(embedded_input.view(self.n_layers,input.size(0),-1), hidden)\n",
    "        elif self.model_type == \"lstm\":\n",
    "          output, hidden = self.lstm(embedded_input.view(self.n_layers,input.size(0),-1), hidden)\n",
    "        elif self.model_type == \"gru\":\n",
    "          output, hidden = self.gru(embedded_input.view(self.n_layers,input.size(0),-1), hidden)\n",
    "\n",
    "        output = self.linear(output)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size, device=None):\n",
    "      \n",
    "        if self.model_type == \"lstm\":\n",
    "            hidden=(torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n",
    "                    torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))\n",
    "        else:\n",
    "          hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0PH6rmSdvOT"
   },
   "source": [
    "# Train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bPhQxG6jY7kk"
   },
   "outputs": [],
   "source": [
    "def train(rnn, input, target, optimizer, criterion):\n",
    "  \n",
    "  stringlength,batch_size,loss  = input.size(1),input.size(0),0\n",
    "  hidden = rnn.init_hidden(batch_size,device)\n",
    "  \n",
    "  rnn.zero_grad()\n",
    "\n",
    "  for i in range(stringlength):\n",
    "    output, hidden = rnn(input[:, i], hidden)\n",
    "\n",
    "    loss += criterion(output.view(batch_size, -1), target[:,i])\n",
    "\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  sigma_loss = loss.item()\n",
    "  average_loss = sigma_loss/batch_size\n",
    "\n",
    "  return  average_loss\n",
    "\n",
    "\n",
    "def eval_test(rnn, inp, target,criterion,batch_size=100):\n",
    "    with torch.no_grad():\n",
    "        hidden = rnn.init_hidden(batch_size, device=device)\n",
    "        loss = 0\n",
    "        for c in range(chunk_len):\n",
    "            output, hidden = rnn(inp[:,c], hidden)\n",
    "            loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "    \n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wkwmq-qdvOU"
   },
   "source": [
    "### Train function\n",
    "\n",
    "**TODO**: Fill in the train function. You should initialize a hidden layer representation using your RNN's `init_hidden` function, set the model gradients to zero, and loop over each time step (character) in the input tensor. For each time step compute the output of the of the RNN and compute the loss over the output and the corresponding ground truth time step in `target`. The loss should be averaged over all time steps. Lastly, call backward on the averaged loss and take an optimizer step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dUbUGZKbl6ye"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def complete(batch_size=100,n_epochs=1500,hidden_size = 100,n_layers = 1,learning_rate = 0.01,model_type = 'rnn',print_every = 100,plot_every = 100):\n",
    "\n",
    "  model = RNN(n_characters, hidden_size, n_characters, model_type=model_type, n_layers=n_layers).to(device)\n",
    "\n",
    "  rnn_optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  start = time.time()\n",
    "  all_losses = []\n",
    "  test_losses = []\n",
    "  loss_avg = 0\n",
    "  test_loss_avg = 0\n",
    "\n",
    "  print(\"Training for %d epochs...\" % n_epochs)\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "      loss = train(model, *load_random_batch(train_text, chunk_len, batch_size), rnn_optimizer, criterion)\n",
    "      loss_avg += loss\n",
    "      \n",
    "      test_loss = eval_test(model, *load_random_batch(test_text, chunk_len, batch_size),criterion)\n",
    "      test_loss_avg += test_loss\n",
    "\n",
    "      if epoch % print_every == 0:\n",
    "          print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "          print(generate(model, 'Wh', 100, device=device), '\\n')\n",
    "\n",
    "      if epoch % plot_every == 0:\n",
    "          print(epoch)\n",
    "          all_losses.append(loss_avg / plot_every)\n",
    "          test_losses.append(test_loss_avg / plot_every)\n",
    "          loss_avg = 0\n",
    "          test_loss_avg = 0\n",
    "  \n",
    "  plt.figure()\n",
    "  plt.plot(all_losses)\n",
    "  plt.plot(test_losses, color='r')\n",
    "\n",
    "  generated_text = evaluate(model, prime_str='Th', predict_len=1000)\n",
    "\n",
    "  print(\"text generation for model type\",model_type,\"   \",generated_text)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYHc3YKytdZL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AY5EW5P3nZFE",
    "outputId": "6f6716ce-651d-4f54-9889-207f9f68d692",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1500 epochs...\n",
      "[0m 29s (100 6%) train loss: 3.7998, test_loss: 1.9724]\n",
      "Whenild, by my gook now whatk go, there newerung\n",
      "The tike of and it tart geem tach re desod wort. I hi \n",
      "\n",
      "100\n",
      "[0m 59s (200 13%) train loss: 3.4836, test_loss: 1.8930]\n",
      "Whey doth the lay way hate and he sour songer, bise throne, his peap me;\n",
      "Me to heards teld worth,\n",
      "That \n",
      "\n",
      "200\n",
      "[1m 29s (300 20%) train loss: 3.3245, test_loss: 1.8252]\n",
      "Who so the love the bewory to mine, would course potched of thein to little\n",
      "Thee?\n",
      "\n",
      "Bishall my sorrenut \n",
      "\n",
      "300\n",
      "[1m 59s (400 26%) train loss: 3.2634, test_loss: 1.8163]\n",
      "What me?\n",
      "\n",
      "AlTAUS:\n",
      "Seeption rucked the servin come the hate abomforse to bricied\n",
      "Ay, it.\n",
      "\n",
      "POLIXENES:\n",
      "Th \n",
      "\n",
      "400\n",
      "[2m 29s (500 33%) train loss: 3.2599, test_loss: 1.7758]\n",
      "What he prought ended on like see in his fame,\n",
      "To have a drantry early than thy pinits\n",
      "Envelten\n",
      "Of in  \n",
      "\n",
      "500\n",
      "[2m 59s (600 40%) train loss: 3.2367, test_loss: 1.8069]\n",
      "Where not\n",
      "a leave him like thus more that an my lurdanand, when that I court air Luke sword a striced  \n",
      "\n",
      "600\n",
      "[3m 28s (700 46%) train loss: 3.1786, test_loss: 1.7982]\n",
      "What here and so the other at disincy the distrued rittle that cold conlied to the war, and be and the \n",
      "\n",
      "700\n",
      "[3m 58s (800 53%) train loss: 3.2147, test_loss: 1.7972]\n",
      "Wher bread, thou are to changed reverty son the warm! he found not with the fair his quly!\n",
      "\n",
      "Mesner:\n",
      "Wh \n",
      "\n",
      "800\n",
      "[4m 28s (900 60%) train loss: 3.1289, test_loss: 1.8089]\n",
      "Whating day bock of cannot to him for the service, wontest whose that any any turn, sir, I be the pard \n",
      "\n",
      "900\n",
      "[4m 58s (1000 66%) train loss: 3.2290, test_loss: 1.7820]\n",
      "Where have pressing of done! on our child.\n",
      "\n",
      "RIVERS:\n",
      "What do it be it were down\n",
      "Do will thinks of my no \n",
      "\n",
      "1000\n",
      "[5m 28s (1100 73%) train loss: 3.1022, test_loss: 1.7678]\n",
      "Whire of the behold fail the bear's hour your hands\n",
      "There bearth, they:\n",
      "Which conwoll? I conwo hole so \n",
      "\n",
      "1100\n",
      "[5m 58s (1200 80%) train loss: 3.1996, test_loss: 1.8035]\n",
      "Wheild, we say makes a days, will at his love?\n",
      "Go, has my lord yis those ever of you that than fight y \n",
      "\n",
      "1200\n",
      "[6m 27s (1300 86%) train loss: 3.1720, test_loss: 1.7627]\n",
      "What is our botning, and and Julied the old be day, you be with a man,\n",
      "And well?\n",
      "\n",
      "MENENIUS:\n",
      "He myself  \n",
      "\n",
      "1300\n",
      "[6m 57s (1400 93%) train loss: 3.1789, test_loss: 1.8090]\n",
      "Whence Edward more some a commandor, words a counts: I as spare with yourself, by this all entreew, an \n",
      "\n",
      "1400\n",
      "[7m 27s (1500 100%) train loss: 3.1773, test_loss: 1.7694]\n",
      "What't:\n",
      "Well, or not me young here, it had I hour well here may will I opness me forshat and the king, \n",
      "\n",
      "1500\n",
      "text generation for model type rnn     ThINCEN EDWARD:\n",
      "I'ld be still and for a sightly to son's latimented in the heavent, could you I took her momelled without are is me as now.\n",
      "\n",
      "ISABELLA:\n",
      "You hands,\n",
      "To do at our and on thy berelfaph,\n",
      "But surp'd hear\n",
      "The tatone, and while not\n",
      "I proy our sort me, and not as betters, the altence in dove vood and ruck, and manciet to God doth service this so the mark thid can the rest or hear us about me, thou keep them, my dricion; in made to my compreat, hear in the look him this astion their strind the mother, which thou after old slet;\n",
      "I dead.\n",
      "\n",
      "KING RICHARD II:\n",
      "What cruel:\n",
      "That more follow sease in them.\n",
      "\n",
      "ESCALUS:\n",
      "O, hermars suorce, but is\n",
      "moor:\n",
      "Who matter, stay'd be light.\n",
      "\n",
      "SAMPSON:\n",
      "She with the is the becomainst it nou pitime sace as the may would I'll my hither\n",
      "I have not: we them.\n",
      "\n",
      "WARWICK:\n",
      "How they foul, be home to daughter alonoth,\n",
      "A soul I shear not with the houst, and from a match.\n",
      "\n",
      "ELYOLL GREY:\n",
      "Ah in the but comes disester'd conwear, her anwere to strike of heaven her not and we th\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn1 = complete(model_type='rnn',hidden_size = 100,n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "G3xJNoQNr2iu",
    "outputId": "3f85af95-d31e-40ec-cae9-8b5249e72e3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1500 epochs...\n",
      "[0m 30s (100 6%) train loss: 3.6550, test_loss: 1.8947]\n",
      "Whand:\n",
      "Jore bested of on the rencessett you, shall siness but this\n",
      "or man the earping that chaver, for \n",
      "\n",
      "100\n",
      "[1m 0s (200 13%) train loss: 3.3513, test_loss: 1.8055]\n",
      "Wharch as of her love wirfom they seathern's with wyour;\n",
      "Cast not our too there to then how and prieft \n",
      "\n",
      "200\n",
      "[1m 31s (300 20%) train loss: 3.1516, test_loss: 1.7707]\n",
      "Whyor dring; go's prom.\n",
      "\n",
      "GLOUCIES:\n",
      "What not all she fond and now to acpure.\n",
      "\n",
      "RATHAMARUCIO:\n",
      "And that th \n",
      "\n",
      "300\n",
      "[2m 1s (400 26%) train loss: 3.0994, test_loss: 1.7123]\n",
      "Whally think way, the life.\n",
      "\n",
      "FGORYOP:\n",
      "Erew kind honourable stand show the marcy\n",
      "down; fear, with me th \n",
      "\n",
      "400\n",
      "[2m 32s (500 33%) train loss: 3.0739, test_loss: 1.7266]\n",
      "Where him.\n",
      "\n",
      "DREY:\n",
      "My proast here are of him!\n",
      "\n",
      "VOLUMNIA:\n",
      "I will be are excellented.\n",
      "\n",
      "GLOUCESTER:\n",
      "I do d \n",
      "\n",
      "500\n",
      "[3m 2s (600 40%) train loss: 3.0314, test_loss: 1.7573]\n",
      "Whall comund dray\n",
      "May in your sear away reppeace,\n",
      "On him seck, afully you say batters,\n",
      "Peraites, that  \n",
      "\n",
      "600\n",
      "[3m 33s (700 46%) train loss: 2.9948, test_loss: 1.6694]\n",
      "Which the daught,\n",
      "But if thou be voice of a shall be her comes expry\n",
      "so should that way for the flatte \n",
      "\n",
      "700\n",
      "[4m 3s (800 53%) train loss: 3.0060, test_loss: 1.6656]\n",
      "Where no cold, what shall besime\n",
      "As fight the noble country sever other good lady\n",
      "Camiss dired but bid \n",
      "\n",
      "800\n",
      "[4m 34s (900 60%) train loss: 2.9109, test_loss: 1.6594]\n",
      "Whath, and them the subjects it\n",
      "wrether thou but we have she earn but how:\n",
      "O, 'tis not helpant with th \n",
      "\n",
      "900\n",
      "[5m 4s (1000 66%) train loss: 2.9368, test_loss: 1.7053]\n",
      "What I apposish of my certure we do it made spirets comfort!\n",
      "\n",
      "Lenter:\n",
      "My grachiender no lives you do a \n",
      "\n",
      "1000\n",
      "[5m 35s (1100 73%) train loss: 2.9659, test_loss: 1.6297]\n",
      "Why wakest is is his squay.\n",
      "\n",
      "GLOUCESTER:\n",
      "So so then it to hear the hostes\n",
      "To may so times accused that \n",
      "\n",
      "1100\n",
      "[6m 5s (1200 80%) train loss: 2.9861, test_loss: 1.7020]\n",
      "Whether is you well.\n",
      "\n",
      "COMINIUS:\n",
      "But now now, why, what but see of down thou, 'Tis inforrar.\n",
      "\n",
      "KING RICH \n",
      "\n",
      "1200\n",
      "[6m 36s (1300 86%) train loss: 2.8612, test_loss: 1.6813]\n",
      "Where's 'sellonour;\n",
      "But no sake must he endushwicks me petty\n",
      "Before our saughter bach, with the world  \n",
      "\n",
      "1300\n",
      "[7m 7s (1400 93%) train loss: 2.8873, test_loss: 1.6667]\n",
      "What hast your heart, 'tis married,\n",
      "To untoundusate the come, me you should\n",
      "crave the word mercution!\n",
      " \n",
      "\n",
      "1400\n",
      "[7m 37s (1500 100%) train loss: 2.8815, test_loss: 1.6653]\n",
      "Whick and what tenderior of your offeced.\n",
      "The word my lord, of the see't of me the using\n",
      "Friut thy goo \n",
      "\n",
      "1500\n",
      "text generation for model type gru     Thally she worthy speed\n",
      "of him, when sir, one Citiet, I state that I\n",
      "will be in this blessic you pride the might\n",
      "As Duke of Marciushy, I sick, my far,\n",
      "For sun me your easuresing to your heart\n",
      "As he have shrus descient let and hart.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Say you'll deeps for my will not partion;\n",
      "For be kindly or wind within this sains\n",
      "Shall be deparctarry and south, yet to roart?\n",
      "\n",
      "First Citizens\n",
      "Hath the bed be wast the Duke o'er-shine,\n",
      "Where my may stoleed of the bloody in my son's become.\n",
      "And before I time at our absolut\n",
      "Insil me lack your spent as a word shold\n",
      "That no crown this to the maring! do not think you give the jeed\n",
      "The take and then then and must be tear with me he.\n",
      "\n",
      "Nurse:\n",
      "More your bedness, though my hour made-mories, it so,\n",
      "For I would here care's in entrain,\n",
      "And safetient we manst with the first now as every direst's the king\n",
      "Than with all, you me to the dangel:\n",
      "For earth our life, go, before I in the our sick,\n",
      "Did the ast with Palated my join'd\n",
      "Do he will be madgs upon the restr\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gru1 = complete(model_type='gru',hidden_size = 100,n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GpPdHThcowgZ",
    "outputId": "398c9196-30fe-466d-c3d6-1f42d85920f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1500 epochs...\n",
      "[0m 30s (100 6%) train loss: 3.7684, test_loss: 1.9779]\n",
      "Whay not wilve my part's your conour make math me not,\n",
      "Whoul with you, what I throre, Forble him, the  \n",
      "\n",
      "100\n",
      "[1m 1s (200 13%) train loss: 3.4177, test_loss: 1.8442]\n",
      "Why sent we roved be dore;\n",
      "Thee hat is this life, the lifowry elver,\n",
      "And us that vice, so his swell;\n",
      "H \n",
      "\n",
      "200\n",
      "[1m 32s (300 20%) train loss: 3.2687, test_loss: 1.7648]\n",
      "What ie ruint me our deach to news,\n",
      "When give to were not pacless that paspeced distach the mides the  \n",
      "\n",
      "300\n",
      "[2m 2s (400 26%) train loss: 3.1006, test_loss: 1.7331]\n",
      "Which mist the ary the better for you hath sheloo,\n",
      "A becon they know; and trisirnes them in the gond o \n",
      "\n",
      "400\n",
      "[2m 33s (500 33%) train loss: 3.1317, test_loss: 1.6936]\n",
      "Whose she shall I there love you thee.\n",
      "\n",
      "ISABELLA:\n",
      "And, part the hearted sent. That cores upon thy such \n",
      "\n",
      "500\n",
      "[3m 4s (600 40%) train loss: 3.0418, test_loss: 1.7074]\n",
      "What thy love to thee, wels.\n",
      "\n",
      "MENENIUS:\n",
      "What with end! That were of her tite,\n",
      "You care of doth as our  \n",
      "\n",
      "600\n",
      "[3m 34s (700 46%) train loss: 3.0300, test_loss: 1.6978]\n",
      "Why word him.\n",
      "\n",
      "First Servant:\n",
      "I trough, and to the sworn and cousest me to the shall that\n",
      "Should truri \n",
      "\n",
      "700\n",
      "[4m 5s (800 53%) train loss: 2.9464, test_loss: 1.6470]\n",
      "What, that not the doubly, like as the commons of speak,\n",
      "The country do'st the moese not them; if the  \n",
      "\n",
      "800\n",
      "[4m 36s (900 60%) train loss: 2.9460, test_loss: 1.6559]\n",
      "What, but the suction.\n",
      "\n",
      "ISABELLA:\n",
      "Yet to my think you, our gracit, and the hears of your like signis,\n",
      " \n",
      "\n",
      "900\n",
      "[5m 7s (1000 66%) train loss: 2.9461, test_loss: 1.6758]\n",
      "Which can welthour from that great\n",
      "Of here\n",
      "The marken's runish'd so much sendows has I devil have brea \n",
      "\n",
      "1000\n",
      "[5m 37s (1100 73%) train loss: 2.8566, test_loss: 1.6564]\n",
      "What's underst thy vilesed with him the dreakes to his honour'd with maid the wants\n",
      "To reasontent-a sa \n",
      "\n",
      "1100\n",
      "[6m 8s (1200 80%) train loss: 2.9283, test_loss: 1.6502]\n",
      "What now, dost with nothing;\n",
      "And Henry's death for so wis the changedly fain\n",
      "the greet thee to the wor \n",
      "\n",
      "1200\n",
      "[6m 39s (1300 86%) train loss: 2.8739, test_loss: 1.6398]\n",
      "What, to him do,\n",
      "That you be juditess do this soldiers?\n",
      "\n",
      "AUTOLYCUS:\n",
      "Why, that when he is the percure;\n",
      " \n",
      "\n",
      "1300\n",
      "[7m 9s (1400 93%) train loss: 2.8816, test_loss: 1.6611]\n",
      "What, by the seem\n",
      "And you, they't to see, the father,\n",
      "Ware this hopes hold so thank your thousand seem \n",
      "\n",
      "1400\n",
      "[7m 40s (1500 100%) train loss: 2.9164, test_loss: 1.6309]\n",
      "Whose since, with him.\n",
      "\n",
      "EDWARD:\n",
      "Ay, stands budiar speak not her queen and with this\n",
      "of a poor are the  \n",
      "\n",
      "1500\n",
      "text generation for model type lstm     Though him death of little.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Then, all him 't he fortune as goodst\n",
      "To said thee, with the Lord owers are in this dead stone or he hath with me\n",
      "That a soul me drink of a sport spently and here:\n",
      "O voicions concutience, and so wercouch in the well\n",
      "With new unkin; to the needs.\n",
      "\n",
      "POMPEY:\n",
      "Go in this leave us for a minds or thing not\n",
      "That that you will not me of son: dest as at\n",
      "With her better noble sword,\n",
      "And can Aufidius of your words and son chasticip:\n",
      "For of speak shall thou art wilt here, but the reasons\n",
      "To that lies like that malingt that night the ofinewel of grief.\n",
      "\n",
      "SICINIUS:\n",
      "He were, I'll go. I would not the mattre houst thy\n",
      "knempppiness affector dims the king\n",
      "Righned and absence common than\n",
      "deper of his preass. What be officest for what's letter like to such more?\n",
      "Had sage, and night, and shame sin.\n",
      "\n",
      "Clown:\n",
      "Aufly prepared that lay to thy death and\n",
      "think of such many, live to same, yes\n",
      "To mier men more hear the duke,\n",
      "So let the made to thy vantious prozence\n",
      "The Duke of \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm1 = complete(model_type='lstm',hidden_size = 100,n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xw4aDdVgr3Q0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBspyLPdrxaX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8D34lXvr-Mc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhxlQNMJsDPX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQ1ZV350dvOV",
    "outputId": "e2806bf0-0d88-49a3-8b0d-3a9c19e45169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thif heart and ratis,\n",
      "Whose\n",
      "But surestle doth his law:\n",
      "Between\n",
      "his vap\n",
      "That now!\n",
      "For live were for you? must show you, and her chance,\n",
      "The will with his intangers,\n",
      "And well: your can have is it.\n",
      "\n",
      "VALUE:\n",
      "\n",
      "First Citizen:\n",
      "He may unstry in us,\n",
      "To most begur.\n",
      "\n",
      "ISABELLA:\n",
      "Good old by your blest own and them by cheeks belightly; and rated me of my blood\n",
      "That is sun\n",
      "And have and have\n",
      "Behod and rights,\n",
      "The priad of my mother of rescied, the nets of the son have the soon mesters stay so love hunst'rth. Father with this were in it, which condinar; blow my father's ras, I our true again merely, there.\n",
      "I am thou arish that that such wide!\n",
      "\n",
      "LUCIO:\n",
      "Well; or buture\n",
      "I'll should begate, again\n",
      "Of the cold me of that he god's back, as by his die! Ruther; begh to with thy king.\n",
      "\n",
      "ROMEO:\n",
      "Come, the peace, the poor lets anough were should down a shalt read him.\n",
      "\n",
      "Second Servingman:\n",
      "We will I prith this kinstruy come, as Grumiet it more we shame;\n",
      "And I call I hurblocions hand, and bold a sweath well you crave by an\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(rnn1, prime_str='Th', predict_len=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0_80gtnmsNq7",
    "outputId": "01fe2ce5-9dfe-43bd-ea79-482461d39748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The be that affected in his\n",
      "come accames the dear not on in is the royous\n",
      "From and way, for to untory a wit stain such\n",
      "That that beggar all and prince, my lord,\n",
      "The come thus me it the better of their calls lips!\n",
      "I said thus him not comely meney,\n",
      "And any tender are not in themselve,\n",
      "Belut shall stains as'dle fair you any that the officing\n",
      "That I shall\n",
      "bincess way such a saw will have not peace.\n",
      "\n",
      "Second Servingman:\n",
      "Why, heart-hoot content the last the Salk!\n",
      "Why, then affus hands of him all husband the remer:\n",
      "But though me this another within shall bear in the fierds\n",
      "Tell or friar hereigh.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Then that prince you are with hope of this.\n",
      "\n",
      "ESCALUS:\n",
      "Look, I seem to so it you:\n",
      "I do is that the resend my sit with more.\n",
      "To they are. Thou art you rough and paffuff,\n",
      "No mine? wind did thee this man more dead.\n",
      "\n",
      "HASTMANANA:\n",
      "He which from his lawurance the sail,\n",
      "Which any in the fither'd course:\n",
      "Whose wither cousin.\n",
      "\n",
      "EDWARD:\n",
      "Those made upon't. For miseral, and she of the gentleman,\n",
      "That \n"
     ]
    }
   ],
   "source": [
    "print(evaluate(gru1, prime_str='Th', predict_len=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ajcL70tJsRQK",
    "outputId": "b875087e-6a1d-4636-9bbc-53fd03144f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Though this state:\n",
      "But thou harded him for I will get pity.\n",
      "\n",
      "MENENIUS:\n",
      "Think me to the suit, which is lost.\n",
      "\n",
      "MENENIUS:\n",
      "And is thy death is this.\n",
      "\n",
      "PAULINA:\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I tell his pain on him to his haince.\n",
      "Forgiving is cannot a man;\n",
      "Though not thee? foresorn'd? or common.\n",
      "\n",
      "JULIET:\n",
      "Some king with a strength's day that prayers.\n",
      "\n",
      "BENVOLIO:\n",
      "Bad late ertaments and the duke to him with thrush:\n",
      "It will that was a man, prebless againty\n",
      "Than not the best and new silent my murder and the full may\n",
      "this being them them I with his scander'd your reason smock\n",
      "sheree cared against crown?\n",
      "\n",
      "BUCKINGHAM:\n",
      "When where Menuce, and I am trumpet shall noble,\n",
      "To the made grace to any purtey but like us.\n",
      "\n",
      "PAULINA:\n",
      "Why I may follow you tell this from your mellous\n",
      "I do be dear let elmand wherein;\n",
      "All thy sun him that neck'st, well her danger'd me:\n",
      "A words and to this lord will marry!\n",
      "But the death with him and more grace,\n",
      "The tongue a better throw was a hurdst;\n",
      "And you villain, and shall here. What shall on them\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(lstm1, prime_str='Th', predict_len=1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-Bwv723dvOV"
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Some things you should try to improve your network performance are:\n",
    "- Different RNN types. Switch the basic RNN network in your model to a GRU and LSTM to compare all three.\n",
    "- Try adding 1 or two more layers\n",
    "- Increase the hidden layer size\n",
    "- Changing the learning rate\n",
    "\n",
    "**TODO:** Try changing the RNN type and hyperparameters. Record your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ft61Qp9moKGk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4b0vG3VoKD-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oohyAIS8oKBw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDeJAwaild-A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
